{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Blackboard.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ryanstwrt/osu-transport/blob/gh-pages/users/stewryan/Blackboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrhCl3wXA_qW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "715c788c-d992-40ba-b46a-9b557a239e12"
      },
      "source": [
        "!pip install osbrain\n",
        "!pip install sklearn-contrib-py-earth\n",
        "!pip install ace\n",
        "!pip install sklearn\n",
        "import osbrain\n",
        "from osbrain import run_nameserver\n",
        "from osbrain import run_agent\n",
        "from osbrain import Agent\n",
        "import time\n",
        "import tables as tb\n",
        "import os\n",
        "import numpy as np\n",
        "import collections\n",
        "from collections import OrderedDict\n",
        "from random import random\n",
        "from pyearth import Earth\n",
        "from google.colab import files\n",
        "import h5py\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn import linear_model\n",
        "from sklearn import gaussian_process\n",
        "from sklearn import neural_network\n",
        "from sklearn import naive_bayes\n",
        "from sklearn import ensemble\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn import model_selection"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting osbrain\n",
            "  Downloading https://files.pythonhosted.org/packages/9d/b6/442c2dcd8e649870af6af7dc78ef3545f30565620c95e9a8af537ef86b47/osbrain-0.6.5.tar.gz\n",
            "Collecting Pyro4>=4.48\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/a2/70bf3d3aa6707eb264b9eb0e0899f3a90a3e062b2178da54e53ba4de2185/Pyro4-4.77-py2.py3-none-any.whl (90kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq>=15.2.0 in /usr/local/lib/python3.6/dist-packages (from osbrain) (17.0.0)\n",
            "Requirement already satisfied: dill!=0.2.7,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from osbrain) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from osbrain) (1.2.2)\n",
            "Collecting serpent>=1.27\n",
            "  Downloading https://files.pythonhosted.org/packages/27/8a/873ccbe1d3d0f81d136686e4d0f38619ac1e718cff7d68f80e364dc52a8c/serpent-1.28-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: osbrain\n",
            "  Building wheel for osbrain (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for osbrain: filename=osbrain-0.6.5-cp36-none-any.whl size=29223 sha256=ea51e95267991141f44a903c12c9c5d9bb71db61c76b1ef038839ac3fdd5ff84\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/e2/0d/a21f92241a5836630a3f773468e2ebe7181016aa23fd5bbbcb\n",
            "Successfully built osbrain\n",
            "Installing collected packages: serpent, Pyro4, osbrain\n",
            "Successfully installed Pyro4-4.77 osbrain-0.6.5 serpent-1.28\n",
            "Collecting sklearn-contrib-py-earth\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/c4/53a24835bafac880036446cc13839471a025b41de1436543f30d15d846c1/sklearn-contrib-py-earth-0.1.0.tar.gz (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.16 in /usr/local/lib/python3.6/dist-packages (from sklearn-contrib-py-earth) (1.3.2)\n",
            "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from sklearn-contrib-py-earth) (0.21.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-contrib-py-earth) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy>=0.16->sklearn-contrib-py-earth) (1.17.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->sklearn-contrib-py-earth) (0.14.0)\n",
            "Building wheels for collected packages: sklearn-contrib-py-earth\n",
            "  Building wheel for sklearn-contrib-py-earth (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn-contrib-py-earth: filename=sklearn_contrib_py_earth-0.1.0-cp36-cp36m-linux_x86_64.whl size=3894212 sha256=126b3f0688e4056e3d2769060af2a47e5aece87d833b5910b706ba0f649b1f62\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8b/9c/4741513102ce3bd0f0227353dacdfbe9a5b0e47c261e45510b\n",
            "Successfully built sklearn-contrib-py-earth\n",
            "Installing collected packages: sklearn-contrib-py-earth\n",
            "Successfully installed sklearn-contrib-py-earth-0.1.0\n",
            "Collecting ace\n",
            "  Downloading https://files.pythonhosted.org/packages/03/3a/d30f9d5f887c47f010bd2097bd7b59caac3d742f1c7cda54c48503c08972/ace-0.3.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ace) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from ace) (1.3.2)\n",
            "Installing collected packages: ace\n",
            "Successfully installed ace-0.3.2\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.17.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_npfQRwAEtS",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to Blackboard System\n",
        "\n",
        "Blackboard systems are used to solve large multi-facited problems in a piece-wise incremental manor. The basic components to a blackboard system can be seen in the bulleted list below.\n",
        "\n",
        "*   Blackboard: Specialized space for agents to write their solutions to a problem too. This is typically stored in memory for quick access, but can also be written to a file for later use. The blackboard can contain specialized infrastructures which ease the reading and writing process for large problems.\n",
        "*   Controller Agent: Initiates the problem, tells other agents when to perform their actions, and when  their results can be added to the blackboard.\n",
        "*   Knowledge Agents: Contain specialized expertise in a problem and contribute to solving the problem at large with their specific piece of knowledge. For a multi-physics problem, this could be solving a set of equations with different methods or solving different sets of equation.\n",
        "\n",
        "Below is a basic blackboard system which involved three agents; a controller and two knowledge agents.\n",
        "The blackboard is used to create a HDF5 file, which the agents will write too, and keep track of the progress of the agents.\n",
        "The simple example has a controller and two agents (A and B) writing the square of values 0 to 9 to the database.\n",
        "Neither agent wants to copy what the other is dointn so they perform a simple check to ensure they are producing unique data. \n",
        "If so, they write the square of the given value to the database.\n",
        "Agent A is working in forward from 0 to 9, while Agent B is working in reverse. \n",
        "At the end, the database has 10 entries ranging from 0 to 9."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOK1lDz5_KQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Blackboard(object):\n",
        "  \"\"\"This class will be the blackboard from which knowledge agents write to and read from.\n",
        "  The state variable keeps track of who is writting to the blackboard, and how many problems have been solved.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    self.agents = []\n",
        "    self.state = {\n",
        "        'problems': 0,\n",
        "        'contributions': [],\n",
        "    }\n",
        "    #Set up the HDF5 databsase\n",
        "    db = tb.open_file(\"blackboard_db\", \"w\")\n",
        "    db.close()\n",
        "\n",
        "  def add_agent(self, agent):\n",
        "    self.agents.append(agent)\n",
        "\n",
        "class Controller(object):\n",
        "  \"\"\"Controls the flow of work distribution in the problem\"\"\"\n",
        "\n",
        "  def __init__(self, blackboard):\n",
        "    self.blackboard = blackboard\n",
        "\n",
        "  def solve_problem(self):\n",
        "    i = 0\n",
        "    while self.blackboard.state['problems'] < 20:\n",
        "      for agent in self.blackboard.agents:\n",
        "        agent.contribute(i)\n",
        "      i+=1        \n",
        "    return self.blackboard.state['contributions']\n",
        "  \n",
        "\n",
        "class baseAgent(object):\n",
        "  \"\"\"Base agent to define __init__ and basic functions\"\"\"\n",
        "\n",
        "  def __init__(self, blackboard, name):\n",
        "    self.blackboard = blackboard\n",
        "    self.name = name\n",
        "    self.root = '/' + self.name\n",
        "    db = tb.open_file(\"blackboard_db\", \"a\")\n",
        "    db.create_group(db.root, self.name)    \n",
        "    db.close()\n",
        "\n",
        "  def contribute(self, i):\n",
        "    pass\n",
        "\n",
        "  def squared(self, x):\n",
        "    return x * x\n",
        "\n",
        "class AgentA(baseAgent):\n",
        "  \"\"\"Agent A will count from 0 to 10\"\"\"\n",
        "\n",
        "  def contribute(self, i):\n",
        "    doubled = self.squared(i)\n",
        "    with tb.open_file(\"blackboard_db\", \"a\") as db:\n",
        "      for node in db:\n",
        "        if 'Val_{}'.format(str(i)) in node:\n",
        "          self.blackboard.state['problems'] = 20\n",
        "      else:\n",
        "        db.create_array(self.root, 'Val_{}'.format(str(i)) , [doubled])\n",
        "    self.blackboard.state['problems'] += 1\n",
        "    self.blackboard.state['contributions'] += [self.__class__.__name__]\n",
        "\n",
        "class AgentB(baseAgent):\n",
        "  \"\"\"Agent B will count in reverse from 10 to 0\"\"\"\n",
        "\n",
        "  def contribute(self, i):\n",
        "    i = 9 - i\n",
        "    doubled = self.squared(i)\n",
        "    with tb.open_file(\"blackboard_db\", \"a\") as db:\n",
        "      for node in db:\n",
        "        if 'Val_{}'.format(str(i)) in node:\n",
        "          self.blackboard.state['problems'] = 20\n",
        "      else:\n",
        "        db.create_array(self.root, 'Val_{}'.format(str(i)) , [doubled])\n",
        "    self.blackboard.state['problems'] += 1\n",
        "    self.blackboard.state['contributions'] += [self.__class__.__name__]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  os.system('rm blackboard_db')\n",
        "  blackboard = Blackboard()\n",
        "  blackboard.add_agent(AgentA(blackboard, 'AgentA'))\n",
        "  blackboard.add_agent(AgentB(blackboard, 'AgentB'))\n",
        "  c = Controller(blackboard)\n",
        "  contributions = c.solve_problem()\n",
        "\n",
        "  h5db = tb.open_file('blackboard_db', 'r+')\n",
        "  print(h5db)\n",
        "  h5db.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rxYjz_Q-1Rw",
        "colab_type": "text"
      },
      "source": [
        "# Multi-Agent Systems\n",
        "\n",
        "Multi-agent systems (MAS) focus on creating individual pieces of software (called agents) who perform some type of task independently of each other and of the user.\n",
        "Agents can communicate with each other via messages to influence what the agents are working on.\n",
        "A central theme for MAS is the autonomy of agents, where they can be designed to work cooperatively or competitively with other agents to accomplish goals.\n",
        "The module [osBrain](https://osbrain.readthedocs.io/en/stable/) is used to create agents in the below examples and a view interactions methods are shown.\n",
        "Some basic nomenclature is important to understand how MAS work in ```osBrain```.\n",
        "\n",
        "\n",
        "*   Agent: Main entity which runs independently of other agents. Its major responsibilities are to poll for incomming messages, process the message, perform some type of action bas on the message, and repeat.\n",
        "*   Proxy: Local objects which enables the user and other agents to access and communicate with a remote agent. Allows us to call methods or access attributes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NfuUMFLAMVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # Create and server to house the multiple agents that will be created\n",
        "    # This is where the agents will reside and how they can be communicated with\n",
        "    ns = run_nameserver()\n",
        "    #The run_agent() method creates a proxy to an agent on a remote server, where name='' allows users to create an alias for that proxy\n",
        "    #Two methods to create an agent; the first creates an agent with no variables assigned to it, the second method creates a variable assiged proxy to an agent\n",
        "    run_agent(name='Exp1')\n",
        "    agent2 = run_agent(name='Exp2')\n",
        "\n",
        "    #Create a proxy to agent Exp1 to easily access it\n",
        "    agent1 = ns.proxy('Exp1')\n",
        "    #Log a message via the proxy Exp1 agent\n",
        "    agent1.log_info(' Hello World, I am tesing an agent')\n",
        "    agent2.log_info('Hello, I am a second agent')\n",
        "\n",
        "    #Determine what agents are alie in the server\n",
        "    for alias in ns.agents():\n",
        "      print(alias)\n",
        "    #shutdown the server as it is no longer needed, otherwise the agents will continue to run\n",
        "    ns.shutdown"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOM5DyGK_Qtr",
        "colab_type": "text"
      },
      "source": [
        "# Multi-Agent Blackboard System (MABS)\n",
        "## Base Classes\n",
        "The following section defines our base classes for the multi-agent blackboard system.\n",
        "To reduce the number of communication lines, the controller agent from the previous sections has been incorporated with the blackboard class.\n",
        "The blackboard class will now act as both the repository for information obtained by the agents, and will determine if/when agents should perform their next action.\n",
        "\n",
        "Along with this, the agents no longer inheret from ```object```, but instead inheret from ```Agent```. \n",
        "```Agent``` is the base class for osBrain which creates a remote object that performs work independently of other agents.\n",
        "These classes are interacted with via a proxy class, which is seen in the ```__main__``` section, where ```ka_a``` is a proxy which allows us to interact with ```KA_A```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI6dPYHT-2Ck",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_message(self, message):\n",
        "  self.log_info('{}'.format(message))\n",
        "\n",
        "class Blackboard(Agent):\n",
        "  def on_init(self):\n",
        "    #Create a connection for others to ask for permission to write to the HDF file\n",
        "    self.bind('REP', alias='ask_permission', handler='ask_permission')\n",
        "    self.bind('PUSH', alias='run_opt_A')\n",
        "    self.bind('PUSH', alias='run_opt_B')\n",
        "    self.open_to_write = True\n",
        "    self.agents = []\n",
        "    self.state = {\n",
        "        'problems': 0,\n",
        "        'contributions': [],\n",
        "    }\n",
        "    db = tb.open_file(\"blackboard_db\", \"w\")\n",
        "    db.close()\n",
        "\n",
        "  def solve_problem(self):\n",
        "    \"\"\"Main loop to solve the problem at hand. First initialize the problem/agents\n",
        "    Then agents will continually ask if addional runs are needed\"\"\"\n",
        "    self.initialize()\n",
        "    return self.state['contributions']\n",
        "\n",
        "  def add_agent(self, agent):\n",
        "    \"\"\"Add an agent to the agent list and create line o fcommunication with it\"\"\"\n",
        "    self.agents.append(agent)\n",
        "    self.connect(agent.addr('run_next_opt'), alias='run_next_opt', handler='ready_agent')\n",
        "\n",
        "  def ask_permission(self, agent_asking):\n",
        "    #Surrogate for ask permission, will eventually include logic to ensure no other agent is accessing HDF\n",
        "\n",
        "    if self.open_to_write:\n",
        "      self.open_to_write = False\n",
        "      log_message(self, 'Agent {} can write to BB'.format(agent_asking))\n",
        "      self.state['problems'] += 1\n",
        "      self.state['contributions'] += [agent_asking]\n",
        "      return True\n",
        "    else:\n",
        "      log_message(self, 'Agent {} cannot write to BB'.format(agent_asking))\n",
        "      return False    \n",
        "\n",
        "  def initialize(self):\n",
        "    for agent in self.agents:\n",
        "      self.run_opt(agent, self.state['problems'])\n",
        "\n",
        "  def ready_agent(self, agent):\n",
        "    self.open_to_write = True\n",
        "    if self.state['problems'] < 9:\n",
        "      self.run_opt(agent, self.state['problems'])\n",
        "    else:\n",
        "      print('Shutting down')\n",
        "      agent.shutdown()\n",
        "\n",
        "  def run_opt(self, agent, i):\n",
        "    name = agent.get_attr('name')\n",
        "    if name == 'ka_a':\n",
        "      self.send('run_opt_A', i)\n",
        "    elif name == 'ka_b':\n",
        "      self.send('run_opt_B', i)\n",
        "\n",
        "\n",
        "class baseKA(Agent):\n",
        "  \"\"\"Base agent to define __init__ and basic functions\"\"\"\n",
        "\n",
        "  def on_init(self):\n",
        "    # This connects to the blackboard and is used to signal when the agent needs to write \n",
        "    # to the blackboard, this is a reply-requestion communication\n",
        "    self.connect(self.bb_addr(self.bb_permission_alias), alias=self.bb_permission_alias)\n",
        "    # This connects to the blackboard. When the blackboard sends the agent a message via the run_opt alias, \n",
        "    # it will trigger the simulate method as the handler to solve the problem\n",
        "    self.connect(self.bb_addr(self.bb_opt_alias), alias=self.bb_opt_alias, handler='simulate')\n",
        "    self.bind('PUSH', alias='run_next_opt')\n",
        "    self.root = '/{}'.format(self.name)\n",
        "    self.db_entry = []\n",
        "    self.doubled = 0\n",
        "    self.val = 0\n",
        "    db = tb.open_file(\"blackboard_db\", \"a\")\n",
        "    db.create_group(db.root, self.name)\n",
        "    db.close()\n",
        "\n",
        "  def write_to_db(self):\n",
        "    # Open the database and check if the result has already been submitted.\n",
        "    # If it has, don't write to DB\n",
        "    with tb.open_file(\"blackboard_db\", \"a\") as db:\n",
        "      for node in db:\n",
        "        if 'Val_{}'.format(self.val) in node:\n",
        "          break\n",
        "      else:\n",
        "        db.create_array(self.root, 'Val_{}'.format(self.val), [self.doubled])\n",
        "\n",
        "  def ask_permission_to_write(self):\n",
        "    \"\"\"Create a loop and continually check to determine if we can write to the database\"\"\"\n",
        "    can_send = False\n",
        "    while can_send == False:\n",
        "      #Ask BB if agent can write to BB\n",
        "      self.send(self.bb_permission_alias, self.name)\n",
        "      can_send = self.recv(self.bb_permission_alias)\n",
        "      time.sleep(0.5)\n",
        "    self.write_to_db()\n",
        "\n",
        "  def simulate(self, i):\n",
        "    pass\n",
        "\n",
        "  def squared(self, x):\n",
        "    self.val = x\n",
        "    return x * x\n",
        "\n",
        "  def ask_bb(self):\n",
        "    \"\"\"Let the Blackboard know the agent is ready to solve another problem\"\"\"\n",
        "    self.send('run_next_opt', self)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuh7rQMlWGfY",
        "colab_type": "code",
        "outputId": "27e8fb4c-bc07-46d8-ec6a-e07274056a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        " class KA_A(baseKA):\n",
        "\n",
        "  def simulate(self, i):\n",
        "    self.doubled = self.squared(i)\n",
        "    time.sleep(1)\n",
        "    self.ask_permission_to_write()\n",
        "    self.ask_bb()\n",
        "\n",
        " class KA_B(baseKA):\n",
        "\n",
        "  def simulate(self, i):\n",
        "    self.doubled = self.squared(i)\n",
        "    time.sleep(1)\n",
        "    self.ask_permission_to_write()\n",
        "    self.ask_bb()    \n",
        "\n",
        "if __name__ == '__main__':\n",
        "  os.system('rm blackboard_db')\n",
        "  ns = run_nameserver()\n",
        "  bb = run_agent(name='blackboard', base=Blackboard)\n",
        "  ka_a = run_agent(name='ka_a', base=KA_A, attributes={'bb_addr':bb.addr,\n",
        "                                                       'bb_permission_alias':'ask_permission',\n",
        "                                                       'bb_opt_alias':'run_opt_A'})\n",
        "  ka_b = run_agent(name='ka_b', base=KA_B, attributes={'bb_addr':bb.addr,\n",
        "                                                       'bb_permission_alias':'ask_permission',\n",
        "                                                       'bb_opt_alias':'run_opt_B'})  \n",
        "  bb.add_agent(ka_a)\n",
        "  bb.add_agent(ka_b)\n",
        "  contributions = bb.solve_problem()\n",
        "\n",
        "  #Let the agent continue to run until only the blackboard agent is left.\n",
        "  while len(ns.agents()) > 1:\n",
        "    time.sleep(5)\n",
        "  else:\n",
        "    h5db = tb.open_file('blackboard_db', 'r+')\n",
        "    print(h5db)\n",
        "    h5db.close()\n",
        "    ns.shutdown()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Broadcast server running on 0.0.0.0:9091\n",
            "NS running on 127.0.0.1:18656 (127.0.0.1)\n",
            "URI = PYRO:Pyro.NameServer@127.0.0.1:18656\n",
            "INFO [2019-11-13 20:17:58.907690] (blackboard): Agent ka_a can write to BB\n",
            "INFO [2019-11-13 20:17:58.910846] (blackboard): Agent ka_b cannot write to BB\n",
            "INFO [2019-11-13 20:17:59.416119] (blackboard): Agent ka_b cannot write to BB\n",
            "INFO [2019-11-13 20:17:59.920627] (blackboard): Agent ka_b can write to BB\n",
            "INFO [2019-11-13 20:18:00.426330] (blackboard): Agent ka_a cannot write to BB\n",
            "INFO [2019-11-13 20:18:00.930736] (blackboard): Agent ka_a can write to BB\n",
            "INFO [2019-11-13 20:18:01.432531] (blackboard): Agent ka_b cannot write to BB\n",
            "INFO [2019-11-13 20:18:01.937761] (blackboard): Agent ka_b can write to BB\n",
            "INFO [2019-11-13 20:18:02.444451] (blackboard): Agent ka_a cannot write to BB\n",
            "INFO [2019-11-13 20:18:02.948057] (blackboard): Agent ka_a can write to BB\n",
            "INFO [2019-11-13 20:18:03.458273] (blackboard): Agent ka_b can write to BB\n",
            "INFO [2019-11-13 20:18:04.459379] (blackboard): Agent ka_a can write to BB\n",
            "INFO [2019-11-13 20:18:04.968743] (blackboard): Agent ka_b can write to BB\n",
            "INFO [2019-11-13 20:18:05.969617] (blackboard): Agent ka_a can write to BB\n",
            "Shutting down\n",
            "INFO [2019-11-13 20:18:06.485117] (blackboard): Agent ka_b can write to BB\n",
            "Shutting down\n",
            "blackboard_db (File) ''\n",
            "Last modif.: 'Wed Nov 13 20:18:06 2019'\n",
            "Object Tree: \n",
            "/ (RootGroup) ''\n",
            "/ka_a (Group) ''\n",
            "/ka_a/Val_0 (Array(1,)) ''\n",
            "/ka_a/Val_1 (Array(1,)) ''\n",
            "/ka_a/Val_3 (Array(1,)) ''\n",
            "/ka_a/Val_5 (Array(1,)) ''\n",
            "/ka_a/Val_7 (Array(1,)) ''\n",
            "/ka_b (Group) ''\n",
            "/ka_b/Val_2 (Array(1,)) ''\n",
            "/ka_b/Val_4 (Array(1,)) ''\n",
            "/ka_b/Val_6 (Array(1,)) ''\n",
            "/ka_b/Val_8 (Array(1,)) ''\n",
            "\n",
            "NS shut down.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W73bAuq1rkQK",
        "colab_type": "text"
      },
      "source": [
        "## Model-based Reflex Agent\n",
        "\n",
        "This examines a class of agents known as model-based reflex agents.\n",
        "In general these agents recieve a stimulus from the environment (aka the blackboard),\n",
        "examine their previous actions, and perform an action based on this.\n",
        "\n",
        "each ```percept``` should countiain if the previous state failed\n",
        "\n",
        "each ```state``` will contain a triple tuple in the form:\n",
        "(current opt scheme, action taken, success of action)\n",
        "\n",
        "Note, that the scheme and action taken are placed in the state before the action is taken. \n",
        "We only find out if the action was a success when the simulation is run and we use the sensor on the environment again \n",
        "\n",
        "```current_state``` will be true or false depending on if the simulation succeeded or failed (given as the ```percept``` from the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAsQNOYtrjCF",
        "colab_type": "code",
        "outputId": "a35b6c98-b4d7-47e2-e4d5-490a5ee4c279",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "class mbra(object):\n",
        "  def __init__(self):\n",
        "    self.state = OrderedDict()\n",
        "    self.action_list = {'new': 1.0, 'validate': 0.0}\n",
        "    self.action_success = True\n",
        "    self.action = 'new'\n",
        "    self.optimization_num = [0,0,0]\n",
        "    self.previous_state_key = 0\n",
        "    self.failed_validation = 0\n",
        "  \n",
        "  def sensor(self, percept):\n",
        "    self.action_success = percept\n",
        "    self.update_state()\n",
        "    self.update_actions()\n",
        "    self.take_action()\n",
        "\n",
        "  def update_state(self):\n",
        "    self.state[self.previous_state_key] = (self.optimization_num, self.action, self.action_success)\n",
        "  \n",
        "  def update_actions(self):\n",
        "    \"\"\"Update actions probabilities based on if the action was new or a validation and if the action was successful or failed\n",
        "       If we fail a validation, we force the validation probability to 100% to explore additional validation \"\"\"\n",
        "    state, action, success = self.state[self.previous_state_key]\n",
        "    if action == 'new':\n",
        "        self.action_list['validate'] += self.action_list['new'] * 0.01\n",
        "        self.action_list['new'] -= self.action_list['new'] * 0.01\n",
        "    elif action == 'validate':\n",
        "      #If an old event fails, that means our assumption is failing, run another old event. \n",
        "      #If it succeeds, slowly increase the probability of running a new one.\n",
        "      if success:\n",
        "        self.action_list['new'] += self.action_list['validate'] / 4\n",
        "        self.action_list['validate'] -= self.action_list['validate'] / 4\n",
        "      else:\n",
        "        self.failed_validation += 1\n",
        "        if failed_validation > 10:\n",
        "          print('Error: Basic assumption is faulty, update scheme.')\n",
        "        else:\n",
        "          print('Warning: Failed a validation check. Underlying assumption may be faulty.')\n",
        "          self.action_list['new'] = 0.0\n",
        "          self.action_list['validate'] = 1.0\n",
        "    else:\n",
        "      print('did not update action list due to unknown action: {}'.format(action))\n",
        "\n",
        "  def take_action(self):\n",
        "    \"\"\"Determine which action to take based on the probability for each action\"\"\"\n",
        "    action_val = random()\n",
        "    self.previous_state_key += 1\n",
        "    if action_val < self.action_list['new']:\n",
        "      self.action = self.run_new_simulation()\n",
        "    else:\n",
        "      self.action = self.run_validation_simulation()\n",
        "  \n",
        "  def run_new_simulation(self):\n",
        "    return 'new'\n",
        "\n",
        "  def run_validation_simulation(self):\n",
        "    return 'validate'\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  test_agent = mbra()\n",
        "  for success in [True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,\n",
        "                  True, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True]:\n",
        "    test_agent.sensor(True)\n",
        "  print(test_agent.action_list)\n",
        "  for k,v in test_agent.state.items():\n",
        "    print(k,v)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'new': 0.7995655945002865, 'validate': 0.2004344054997135}\n",
            "0 ([0, 0, 0], 'new', True)\n",
            "1 ([0, 0, 0], 'new', True)\n",
            "2 ([0, 0, 0], 'new', True)\n",
            "3 ([0, 0, 0], 'new', True)\n",
            "4 ([0, 0, 0], 'new', True)\n",
            "5 ([0, 0, 0], 'new', True)\n",
            "6 ([0, 0, 0], 'new', True)\n",
            "7 ([0, 0, 0], 'new', True)\n",
            "8 ([0, 0, 0], 'new', True)\n",
            "9 ([0, 0, 0], 'new', True)\n",
            "10 ([0, 0, 0], 'new', True)\n",
            "11 ([0, 0, 0], 'validate', True)\n",
            "12 ([0, 0, 0], 'new', True)\n",
            "13 ([0, 0, 0], 'new', True)\n",
            "14 ([0, 0, 0], 'validate', True)\n",
            "15 ([0, 0, 0], 'new', True)\n",
            "16 ([0, 0, 0], 'new', True)\n",
            "17 ([0, 0, 0], 'new', True)\n",
            "18 ([0, 0, 0], 'new', True)\n",
            "19 ([0, 0, 0], 'new', True)\n",
            "20 ([0, 0, 0], 'new', True)\n",
            "21 ([0, 0, 0], 'new', True)\n",
            "22 ([0, 0, 0], 'new', True)\n",
            "23 ([0, 0, 0], 'new', True)\n",
            "24 ([0, 0, 0], 'new', True)\n",
            "25 ([0, 0, 0], 'new', True)\n",
            "26 ([0, 0, 0], 'new', True)\n",
            "27 ([0, 0, 0], 'validate', True)\n",
            "28 ([0, 0, 0], 'new', True)\n",
            "29 ([0, 0, 0], 'new', True)\n",
            "30 ([0, 0, 0], 'new', True)\n",
            "31 ([0, 0, 0], 'new', True)\n",
            "32 ([0, 0, 0], 'new', True)\n",
            "33 ([0, 0, 0], 'new', True)\n",
            "34 ([0, 0, 0], 'new', True)\n",
            "35 ([0, 0, 0], 'new', True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd3lvGn46Wqd",
        "colab_type": "text"
      },
      "source": [
        "# Multivariate Adaptive Regression Splines\n",
        "\n",
        "MARS is flexible regression analysis tool which searches for interactions and non-linear relationships, while ultimately trying to maintain as simple of a relationship as possible.\n",
        "This work utilizes `py-earth`, which is a python adaption of Friedmans's MARS [Fri91].\n",
        "Often times these models can be described as linear models in a higher dimensional basis space.\n",
        "Each term in the model corresponds to a hinge function, where hinge functions are 0 everywhere except where it is equal to its argument.\n",
        "This means each model represents a portion of the overall function, where the linear combination of these models creates the full function.\n",
        "\n",
        "The algorithm consists of two stages.\n",
        "The first stage is considered the forward pass which attempts to minimized the squared error loss in the data. \n",
        "This typically will overfit the data and as such a backwards (or pruning) pass is implemented. \n",
        "This selects s subset of terms which produce a locally minimal generalized cross-validation score, which penalizes complexity in the model.\n",
        "The final results creates basis function that is non-linear in the original space and is likely to generalize to the problem set well.\n",
        "\n",
        "\n",
        "[Fri91] JH Friedman. Multivariate adaptive regression splines. The annals of statistics, 19(1):1–67, 1991. URL: http://www.jstor.org/stable/10.2307/2241837."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmnwzIcE4mod",
        "colab_type": "code",
        "outputId": "37b51c2a-2dd8-48be-d898-1239394ea6a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        }
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "#Create some fake data\n",
        "np.random.seed(0)\n",
        "x_1 = [0, 0, 0] # This would be one set of data, for example number of experiments fo A,B, and C\n",
        "x_2 = [1, 2, 3] # This woudl be another set of data\n",
        "X = [x_1,x_2]\n",
        "for i in range(3):\n",
        "  X.append([(i+2) * x for x in x_2]) # More generated data\n",
        "\n",
        "X = np.array(X)\n",
        "y = [[-5, -4, -3, 1.1]] #Set of dependent variables associated with X_1\n",
        "for i in range(4):\n",
        "  y.append([(0.99) * y for y in y[i]]) #set of depended variables associated with x_2, 3 et.c\n",
        "\n",
        "print(X)\n",
        "\n",
        "#Fit an Earth model\n",
        "model = Earth()\n",
        "X_2 = np.array([[15, 9, 12], [5,2,22], [5,9,12]])\n",
        "model.fit(X,y)\n",
        "\n",
        "#Print the model\n",
        "print(model.trace())\n",
        "print(model.summary())\n",
        "\n",
        "#Plot the model\n",
        "y_hat = model.predict(X_2)\n",
        "for val in y_hat:\n",
        "  print(val)\n",
        "pyplot.figure()\n",
        "pyplot.plot(X[:,1],y,'r.')\n",
        "pyplot.plot(X_2[:,1],y_hat,'b.')\n",
        "pyplot.xlabel('x_6')\n",
        "pyplot.ylabel('y')\n",
        "pyplot.title('Simple Example')\n",
        "pyplot.show()\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0  0  0]\n",
            " [ 1  2  3]\n",
            " [ 2  4  6]\n",
            " [ 3  6  9]\n",
            " [ 4  8 12]]\n",
            "Forward Pass\n",
            "---------------------------------------------------------------\n",
            "iter  parent  var  knot  mse       terms  gcv    rsq    grsq   \n",
            "---------------------------------------------------------------\n",
            "0     -       -    -     0.002485  1      0.004  0.000  0.000  \n",
            "1     0       0    -1    0.000000  2      0.000  1.000  1.000  \n",
            "---------------------------------------------------------------\n",
            "Stopping Condition 1: Achieved RSQ value within threshold of 1\n",
            "\n",
            "Pruning Pass\n",
            "--------------------------------------------\n",
            "iter  bf  terms  mse   gcv    rsq    grsq   \n",
            "--------------------------------------------\n",
            "0     -   2      0.00  0.000  1.000  1.000  \n",
            "1     1   1      0.00  0.004  0.000  0.000  \n",
            "--------------------------------------------\n",
            "Selected iteration: 0\n",
            "\n",
            "Earth Model\n",
            "------------------------------------------------------------------------------------\n",
            "Basis Function  Pruned  Coefficient 0  Coefficient 1  Coefficient 2  Coefficient 3  \n",
            "------------------------------------------------------------------------------------\n",
            "(Intercept)     No      -4.9995        -3.9996        -2.9997        1.09989        \n",
            "x0              No      0.0492545      0.0394036      0.0295527      -0.010836      \n",
            "------------------------------------------------------------------------------------\n",
            "MSE: 0.0000, GCV: 0.0000, RSQ: 1.0000, GRSQ: 0.9997\n",
            "[-4.26068664 -3.40854931 -2.55641198  0.93735106]\n",
            "[-4.75323154 -3.80258523 -2.85193892  1.04571094]\n",
            "[-4.75323154 -3.80258523 -2.85193892  1.04571094]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyearth/earth.py:802: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  pruning_passer.run()\n",
            "/usr/local/lib/python3.6/dist-packages/pyearth/earth.py:1055: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
            "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
            "  coef, resid = np.linalg.lstsq(B, weighted_y[:, i])[0:2]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEXCAYAAACkpJNEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKANAkhplAEhSowwASWrU/wfZHcPNadvNkQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPZK43nbCFC7",
        "colab_type": "text"
      },
      "source": [
        "Investigate predictor (extrapolation) methods for determining where to run simulations. We can then continually update the method with new data points.\n",
        "Note: This should be done for a single variable. i.e. if we have 3 ABR, 3 fertile, and 3 materials test and we are optimizing for materials tests then only add assemblies of the materials test type.\n",
        "\n",
        "1. Run the simulation for two problems\n",
        "2. Utilize a linear interpolation to find the point where we will violate a limit.\n",
        "3. Select a point which is halfway to that point, and run a simulation.\n",
        "4. Determine if a lienar regression holds true for this fit.\n",
        "  a. If it does hold true, find a the point at which we violate a limit.\n",
        "  b. If it does not hold true, increase to a higher polynomial formula and select a point based on this.\n",
        "5. Run the simulation for the current point. Repeat 3. - 5. until we reach the limiting problem.\n",
        "\n",
        "Alternativley we could use the following approach\n",
        "1. Run the simulation for two problems\n",
        "2. Check the blackboard and determine how many solutions are present.\n",
        "  1. If enough solutions are present, implement a MARS/ACE regression to determine violation point\n",
        "  2. If not, utilize a linear interpolation for each of the objectives to find the point where we violate a limit.\n",
        "3. Select a a point below this value and run the simulation, repeat steps 2. - 3. until you find optimal point\n",
        "\n",
        "\n",
        "ACE might be beneficial to use in the final analysis of rthe dataset, where MARS might be better for the actual interpolation/extrapolation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biy5riBxSGjl",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation of Surrogate Models for Small and Continually Growing Datasets\n",
        "\n",
        "This section aims to find an optimal relationship between various surrogate models and their applicability to interpolating/extrapolating results in a databse. For this evaluation, seven surrogate models will be examined they are as follows\n",
        "*   Linear Regression\n",
        "*   Multi-Adaptive Regression Splines\n",
        "*   Gaussian Process\n",
        "*   Artificial Neural Networks (Multi-level Perceptron Regression)\n",
        "*   Naive-Bayes Regression\n",
        "*   Ensemble Methods\n",
        "*   Support Vector Machines\n",
        "For each surrogate, a training model will be created and compared with a test database.\n",
        "\n",
        "A small databse with SFR core designs will first be examined based on work previous work.\n",
        "For each objective function, all of the surrogate models will be created and the R^2 value for both the training and test set will be used to determine which surrogate creates the best representation.\n",
        "This will first be performed with an interpolation scheme, and following this, extrapolation will be examinined."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zSVtezbUZZH",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "1bfae02d-2849-433d-e594-27e2b3583056"
      },
      "source": [
        "uploaded = files.upload()\n",
        "h5file = h5py.File(r'sfr_db_new.h5', 'r+')\n",
        "uploaded = files.upload()\n",
        "h5file2 = h5py.File(r'sfr_db.h5', 'r+')\n",
        "uploaded = files.upload()\n",
        "h5file3 = h5py.File(r'sfr_db_test.h5', 'r+')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e170d051-cc21-406e-86ed-5b9d1aa4b4a8\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e170d051-cc21-406e-86ed-5b9d1aa4b4a8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sfr_db_new.h5 to sfr_db_new.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f597c305-5b75-4d5f-8832-908dbdd11dc4\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-f597c305-5b75-4d5f-8832-908dbdd11dc4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sfr_db.h5 to sfr_db.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a320454c-f068-4a26-98c8-4650e26e52c3\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-a320454c-f068-4a26-98c8-4650e26e52c3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving sfr_db_test.h5 to sfr_db_test.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEIhvQxUUx3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_database(database, reactor_vars, obj_vars):\n",
        "  db = h5py.File(database, 'r+')\n",
        "  # Create a dict of reactor name : reactor attributes to fill the data frame\n",
        "  reactorDict = {}\n",
        "  for r in h5file.keys():\n",
        "    reactor = h5file[r]\n",
        "    dataDict = {}\n",
        "    for k, v in reactor.items():\n",
        "      if k[0] != 'F':\n",
        "        dataDict[k] = list(v)\n",
        "    reactorDict[r] = dataDict\n",
        "\n",
        "  reactorData = pd.DataFrame(reactorDict)\n",
        "  reactorData = reactorData.T\n",
        "  pu_content_dict = {}\n",
        "  for num, enr in reactorData['enrichment'].items():\n",
        "    if enr[0] == '15Pu12U10Zr':\n",
        "      pu_content_dict[num] = 0.55555555\n",
        "    elif enr[0] == '27U10Zr':\n",
        "      pu_content_dict[num] = 0.0\n",
        "    elif enr[0] == '27Pu0U10Zr':\n",
        "      pu_content_dict[num] = 1.0\n",
        "    elif enr[0] == '7Pu20U10Zr':\n",
        "      pu_content_dict[num] = 0.25\n",
        "    elif enr[0] == '20Pu7U10Zr':\n",
        "      pu_content_dict[num] = 0.75             \n",
        "    else:\n",
        "      print(num, enr)\n",
        "\n",
        "  reactorData['pu_content'] = pu_content_dict.values()\n",
        "  reactorData['pu_content'] = reactorData['pu_content'].apply(lambda x : [x])\n",
        "\n",
        "\n",
        "  # Create a a coordinate system via the variables for interpolator\n",
        "  var_array = []\n",
        "  mars_coordinates = []\n",
        "  for var in reactor_vars.keys():\n",
        "    var_list = []\n",
        "    var_list_mars = []\n",
        "    for data_point in reactorData[var]:\n",
        "      var_list.append(data_point[0])\n",
        "    var_array.append(var_list)\n",
        "  coordinates = list(zip(*var_array))\n",
        "\n",
        "  #print(coordinates)\n",
        "  for x in coordinates:\n",
        "      mars_coordinates.append(list(x))\n",
        "  mars_coordinates = np.array(mars_coordinates)\n",
        "  # Create a list of objectives to solve for, and a list of known values\n",
        "  # for the objectives \n",
        "  obj_dict = {}\n",
        "  interp = {}\n",
        "  obj_list_tot = []\n",
        "  for obj in obj_vars:\n",
        "    obj_list = []\n",
        "    for data_point in reactorData[obj]:\n",
        "      try:\n",
        "        obj_list.append(data_point[0])\n",
        "      except IndexError:\n",
        "        obj_list.append(data_point)\n",
        "    obj_list_tot.append(obj_list)\n",
        "    obj_dict[obj] = obj_list\n",
        "  \n",
        "  mars_objectives = []\n",
        "  for x in list(zip(*obj_list_tot)):\n",
        "    mars_objectives.append(list(x))\n",
        "  mars_objectives = np.array(mars_objectives)\n",
        "\n",
        "  return mars_coordinates, mars_objectives\n",
        "\n",
        "\n",
        "def train_surrogate_models(variables_objectives):\n",
        "  # Split our database into a training and testing set to ensure we get accurate R^2 values\n",
        "  var_train, var_test, obj_train, obj_test = train_test_split(variables, objectives)\n",
        "\n",
        "  # Scale our sets to ensure our surrogate models can handle the data\n",
        "  var_train_scaler = StandardScaler()\n",
        "  var_test_scaler = StandardScaler()\n",
        "  obj_train_scaler = StandardScaler()\n",
        "  obj_test_scaler = StandardScaler()\n",
        "  var_train_scaler.fit(var_train)\n",
        "  var_test_scaler.fit(var_test)\n",
        "  obj_train_scaler.fit(obj_train)\n",
        "  obj_test_scaler.fit(obj_test)\n",
        "\n",
        "  # Transform out data into the scaled dimension\n",
        "  scaled_var_train = var_train_scaler.transform(var_train)\n",
        "  scaled_var_test  = var_test_scaler.transform(var_test)\n",
        "  scaled_obj_train = obj_train_scaler.transform(obj_train)\n",
        "  scaled_obj_test  = obj_test_scaler.transform(obj_test)\n",
        "\n",
        "  # Create model for Linear\n",
        "  linear = linear_model.LinearRegression()\n",
        "  linear_fit = linear.fit(scaled_var_train,scaled_obj_train)\n",
        "  linear_score = linear.score(scaled_var_test,scaled_obj_test)\n",
        "  # Create model for Ridge\n",
        "  ridge = linear_model.Ridge()\n",
        "  ridge_fit = ridge.fit(scaled_var_train,scaled_obj_train)\n",
        "  ridge_score = ridge.score(scaled_var_test,scaled_obj_test)    \n",
        "  # Create model for MARS\n",
        "  mars = Earth()\n",
        "  parameters = {'endspan_alpha':(0.01, 0.05, 0.1, 0.25), 'minspan_alpha':(0.01, 0.05, 0.1, 0.25)}\n",
        "  mars_fit = mars.fit(scaled_var_train,scaled_obj_train)\n",
        "  mars_score = mars.score(scaled_var_test,scaled_obj_test)\n",
        "  #Create model for Gaussian Process\n",
        "  gpr = gaussian_process.GaussianProcessRegressor(optimizer='fmin_l_bfgs_b')\n",
        "  parameters = {'alpha':(0.0001,0.001,0.01,0.1), 'kernel': (gaussian_process.kernels.Matern, gaussian_process.kernels.RationalQuadratic)}\n",
        "  gpr_fit = gpr.fit(scaled_var_train,scaled_obj_train)\n",
        "  gpr_score = gpr.score(scaled_var_test,scaled_obj_test)\n",
        "  # Create model for ANN\n",
        "  ann = neural_network.MLPRegressor()\n",
        "  parameters = {'solver':('lbfgs','sgd'), 'activation':('tanh','relu',), 'alpha':(0.0001,0.001,0.01,0.1)}\n",
        "  #ann = model_selection.GridSearchCV(ann, parameters)\n",
        "  ann_fit = ann.fit(scaled_var_train,scaled_obj_train)\n",
        "  ann_score = ann.score(scaled_var_test,scaled_obj_test)\n",
        "  # Create model for random forrest (should be used for interpolation only!)\n",
        "  rf = ensemble.RandomForestRegressor(n_estimators=100)\n",
        "  rf_fit = rf.fit(scaled_var_train,scaled_obj_train)\n",
        "  rf_score = rf.score(scaled_var_test,scaled_obj_test)\n",
        "\n",
        "  return [(linear, linear_fit), (ridge, ridge_fit), (mars, mars_fit), (gpr, gpr_fit), (ann, ann_fit), (rf, rf_fit), \n",
        "          var_train_scaler]\n",
        "\n",
        "\n",
        "def surrogate_evaluation(variables, objectives, test_var):\n",
        "\n",
        "  test = np.array([[x for x in test_var.values()]])\n",
        "\n",
        "  # Split our database into a training and testing set to ensure we get accurate R^2 values\n",
        "  var_train, var_test, obj_train, obj_test = train_test_split(variables, objectives)\n",
        "\n",
        "  # Scale our sets to ensure our surrogate models can handle the data\n",
        "  var_train_scaler = StandardScaler()\n",
        "  var_test_scaler = StandardScaler()\n",
        "  obj_train_scaler = StandardScaler()\n",
        "  obj_test_scaler = StandardScaler()\n",
        "  var_train_scaler.fit(var_train)\n",
        "  var_test_scaler.fit(var_test)\n",
        "  obj_train_scaler.fit(obj_train)\n",
        "  obj_test_scaler.fit(obj_test)\n",
        "\n",
        "  # Transform out data into the scaled dimension\n",
        "  scaled_var_train = var_train_scaler.transform(var_train)\n",
        "  scaled_var_test  = var_test_scaler.transform(var_test)\n",
        "  scaled_obj_train = obj_train_scaler.transform(obj_train)\n",
        "  scaled_obj_test  = obj_test_scaler.transform(obj_test)\n",
        "\n",
        "  # Transform our desired solution into the transform space\n",
        "  scaled_test = var_train_scaler.transform(test)\n",
        "\n",
        "  # Create model for Linear\n",
        "  linear = linear_model.LinearRegression()\n",
        "  linear_fit = linear.fit(scaled_var_train,scaled_obj_train)\n",
        "  linear_score = linear.score(scaled_var_test,scaled_obj_test)\n",
        "  # Create model for Lasso\n",
        "  lasso = linear_model.Lasso()\n",
        "  lasso_fit = lasso.fit(scaled_var_train,scaled_obj_train)\n",
        "  lasso_score = lasso.score(scaled_var_test,scaled_obj_test)\n",
        "  # Create model for Ridge\n",
        "  ridge = linear_model.Ridge()\n",
        "  ridge_fit = ridge.fit(scaled_var_train,scaled_obj_train)\n",
        "  ridge_score = ridge.score(scaled_var_test,scaled_obj_test)    \n",
        "  # Create model for MARS\n",
        "  mars = Earth()\n",
        "  parameters = {'endspan_alpha':(0.01, 0.05, 0.1, 0.25), 'minspan_alpha':(0.01, 0.05, 0.1, 0.25)}\n",
        "  mars = model_selection.GridSearchCV(mars, parameters)\n",
        "  mars_fit = mars.fit(scaled_var_train,scaled_obj_train)\n",
        "  mars_score = mars.score(scaled_var_test,scaled_obj_test)\n",
        "  #Create model for Gaussian Process\n",
        "  gpr = gaussian_process.GaussianProcessRegressor(optimizer='fmin_l_bfgs_b')\n",
        "  parameters = {'alpha':(0.0001,0.001,0.01,0.1), 'kernel': (gaussian_process.kernels.Matern, gaussian_process.kernels.RationalQuadratic)}\n",
        "  gpr_fit = gpr.fit(scaled_var_train,scaled_obj_train)\n",
        "  gpr_score = gpr.score(scaled_var_test,scaled_obj_test)\n",
        "  # Create model for ANN\n",
        "  ann = neural_network.MLPRegressor()\n",
        "  parameters = {'solver':('lbfgs','sgd'), 'activation':('tanh','relu',), 'alpha':(0.0001,0.001,0.01,0.1)}\n",
        "  #ann = model_selection.GridSearchCV(ann, parameters)\n",
        "  ann_fit = ann.fit(scaled_var_train,scaled_obj_train)\n",
        "  ann_score = ann.score(scaled_var_test,scaled_obj_test)\n",
        "  # Create model for random forrest (should be used for interpolation only!)\n",
        "  rf = ensemble.RandomForestRegressor(n_estimators=100)\n",
        "  rf_fit = rf.fit(scaled_var_train,scaled_obj_train)\n",
        "  rf_score = rf.score(scaled_var_test,scaled_obj_test)\n",
        "  return [linear_score, ridge_score, mars_score, gpr_score, ann_score, rf_score]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQhnekecZhd1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "var_tot, obj_tot = reshape_database(r'sfr_db_test.h5', {'height': 0.0, 'smear': 0.0, 'pu_content': 0.0}, ['keff', 'void_coeff', 'doppler_coeff'])\n",
        "var_keff, obj_keff = reshape_database(r'sfr_db.h5', {'height': 0.0, 'smear': 0.0, 'pu_content': 0.0}, ['keff'])\n",
        "var_void, obj_void = reshape_database(r'sfr_db.h5', {'height': 0.0, 'smear': 0.0, 'pu_content': 0.0}, ['void_coeff'])\n",
        "var_dopp, obj_dopp = reshape_database(r'sfr_db.h5', {'height': 0.0, 'smear': 0.0, 'pu_content': 0.0}, ['doppler_coeff'])\n",
        "\n",
        "\n",
        "score_list = []\n",
        "keff_list = []\n",
        "void_list = []\n",
        "dopp_list = []\n",
        "\n",
        "for i in range(100):\n",
        "#  score_list.append(surrogate_evaluation(var_tot, obj_tot, {'height':61.37, 'smear':51.58, 'pu_content':0.7340}))\n",
        "  keff_list.append(surrogate_evaluation(var_keff, obj_keff, {'height':61.37, 'smear':51.58, 'pu_content':0.7340}))\n",
        "  void_list.append(surrogate_evaluation(var_void, obj_void, {'height':61.37, 'smear':51.58, 'pu_content':0.7340}))\n",
        "  dopp_list.append(surrogate_evaluation(var_dopp, obj_dopp, {'height':61.37, 'smear':51.58, 'pu_content':0.7340}))\n",
        "  \n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_tot, obj_tot, {'height':59.72, 'smear':50.01, 'pu_content':0.8694})\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_tot, obj_tot, {'height':71.06, 'smear':55.77, 'pu_content':0.3536})\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_dopp, obj_dopp, {'height':71.06, 'smear':55.77, 'pu_content':0.3536})\n",
        "\n",
        "#print(\"\")\n",
        "#print(\"**************Extrapolation****************\")\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_tot, obj_tot, {'height':60, 'smear':75, 'pu_content': 0.0})\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_keff, obj_keff, {'height':60, 'smear':75, 'pu_content': 0.0})\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_void, obj_void, {'height':60, 'smear':75, 'pu_content': 0.0})\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_dopp, obj_dopp, {'height':60, 'smear':75, 'pu_content': 0.0})\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_tot, obj_tot, {'height':60, 'smear':75, 'pu_content': 1.0})\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_keff, obj_keff, {'height':60, 'smear':75, 'pu_content': 1.0})\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_void, obj_void, {'height':60, 'smear':75, 'pu_content': 1.0})\n",
        "#print(\"\")\n",
        "#obj_funk = surrogate_evaluation(var_dopp, obj_dopp, {'height':60, 'smear':75, 'pu_content': 1.0})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1fWAV1Gvs5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "test_list = copy.deepcopy(score_list)\n",
        "new_list = pd.DataFrame(test_list)\n",
        "new_keff = pd.DataFrame(copy.deepcopy(keff_list))\n",
        "new_void = pd.DataFrame(copy.deepcopy(void_list))\n",
        "new_dopp = pd.DataFrame(copy.deepcopy(dopp_list))\n",
        "#test_100_list = pd.DataFrame(test_list)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boLHWpfUxgNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "29e43d7b-e275-49ca-f3f5-0fb197757109"
      },
      "source": [
        "mean_keff = new_keff.mean(axis = 0)\n",
        "mean_void = new_void.mean(axis = 0)\n",
        "mean_dopp = new_dopp.mean(axis = 0)\n",
        "\n",
        "std_dev_keff = new_keff.std( axis = 0)\n",
        "std_dev_void = new_void.std( axis = 0)\n",
        "std_dev_dopp = new_dopp.std( axis = 0)\n",
        "\n",
        "\n",
        "#print(test_100_list[2].sem)\n",
        "print(mean_keff)\n",
        "print(std_dev_keff)\n",
        "print(\"\")\n",
        "print(mean_void)\n",
        "print(std_dev_void)\n",
        "print(\"\")\n",
        "print(mean_dopp)\n",
        "print(std_dev_dopp)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.938675\n",
            "1    0.940445\n",
            "2    0.937754\n",
            "3    0.928501\n",
            "4    0.942451\n",
            "5    0.862796\n",
            "dtype: float64\n",
            "0    0.043735\n",
            "1    0.043002\n",
            "2    0.069339\n",
            "3    0.050037\n",
            "4    0.041512\n",
            "5    0.077075\n",
            "dtype: float64\n",
            "\n",
            "0    0.915163\n",
            "1    0.916179\n",
            "2    0.878676\n",
            "3    0.916549\n",
            "4    0.934374\n",
            "5    0.848731\n",
            "dtype: float64\n",
            "0    0.045486\n",
            "1    0.043421\n",
            "2    0.704143\n",
            "3    0.063549\n",
            "4    0.050069\n",
            "5    0.090628\n",
            "dtype: float64\n",
            "\n",
            "0    0.864810\n",
            "1    0.866253\n",
            "2    0.864803\n",
            "3    0.832020\n",
            "4    0.889655\n",
            "5    0.814429\n",
            "dtype: float64\n",
            "0    0.051106\n",
            "1    0.050456\n",
            "2    0.053027\n",
            "3    0.097207\n",
            "4    0.060349\n",
            "5    0.124728\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llnngq9xzaxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "580655a2-9f62-4b28-c27e-c7393f31e763"
      },
      "source": [
        "mean = new_list.mean(axis = 0)\n",
        "std_dev = new_list.std( axis = 0)\n",
        "print(mean)\n",
        "print(std_dev)"
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    0.906589\n",
            "1    0.908028\n",
            "2    0.883221\n",
            "3    0.891067\n",
            "4    0.921305\n",
            "5    0.837935\n",
            "dtype: float64\n",
            "0    0.040640\n",
            "1    0.039646\n",
            "2    0.582896\n",
            "3    0.060977\n",
            "4    0.042351\n",
            "5    0.094371\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}